{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load(\"300features_40minwords_10context\")\n",
    "num_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03144343, -0.02232238, -0.02028987, ..., -0.02405546,\n",
       "         0.09926601,  0.049621  ],\n",
       "       [-0.05746495, -0.05549316, -0.11874807, ..., -0.03157035,\n",
       "         0.05097324,  0.01731471],\n",
       "       [ 0.00215511, -0.00649544,  0.01320117, ..., -0.0620345 ,\n",
       "         0.02614006,  0.04123367],\n",
       "       ...,\n",
       "       [-0.06553942, -0.01146925,  0.15460777, ...,  0.09524195,\n",
       "        -0.07421808, -0.00829083],\n",
       "       [-0.01500735, -0.00073907,  0.00629002, ...,  0.02063346,\n",
       "        -0.01849476, -0.04222548],\n",
       "       [-0.06901131, -0.05137084,  0.11262897, ..., -0.06355549,\n",
       "        -0.07343313, -0.02937378]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"./datasets/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(\"./datasets/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "unlabeled_train = pd.read_csv(\"./datasets/unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    \n",
    "    words = letters_only.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('english'))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features), dtype='float32')\n",
    "    nwords = 0\n",
    "    \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords += 1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype='float32')\n",
    "    for review in reviews:\n",
    "        if counter % 1000 == 0:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter += 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "Creating average feature vecs for text reviews\n",
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, num_features)\n",
    "print(\"Creating average feature vecs for text reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# forest = RandomForestClassifier( n_estimators = 100 )\n",
    "\n",
    "# print (\"Fitting a random forest to labeled training data...\")\n",
    "# forest = forest.fit( trainDataVecs, train[\"sentiment\"] )\n",
    "\n",
    "# # Test & extract results \n",
    "# result = forest.predict( testDataVecs )\n",
    "\n",
    "# # Write the test results \n",
    "# output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "# output.to_csv( \"result_03.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  0.00021886825561523438 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "word_vertors = model.wv.syn0\n",
    "num_clusters =int( word_features.shape[0] / 5)\n",
    "kmeans_clustering = KMeans(n_clusters=int(num_clusters))\n",
    "idx = kmeans_clustering.fit_predict(word_features)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "['lamarr', 'hedy', 'olga']\n",
      "Cluster 1\n",
      "['service', 'staff', 'safety', 'demand', 'firm', 'insurance', 'services', 'protection', 'reward', 'request', 'employment', 'ransom', 'institute', 'escort', 'volunteer', 'debts', 'payment', 'arrange', 'taxes']\n",
      "Cluster 2\n",
      "['jealous', 'scheming', 'bitchy', 'conniving', 'distraught', 'timid', 'virginal', 'headstrong', 'tomboy', 'plucky']\n",
      "Cluster 3\n",
      "['rear', 'statue', 'closeup', 'silhouette', 'parting', 'nary']\n",
      "Cluster 4\n",
      "['fabric']\n",
      "Cluster 5\n",
      "['landmark', 'quintessential', 'monumental', 'eklavya', 'triumphant', 'nadir', 'marking', 'crowning', 'purest']\n",
      "Cluster 6\n",
      "['alex', 'mills', 'hector', 'edison', 'wolverine', 'cabot', 'hatton', 'duryea', 'sasha', 'merrill', 'sloan', 'bannister', 'mantee', 'mendoza']\n",
      "Cluster 7\n",
      "['tearing', 'stepping', 'pouring', 'poured', 'tripping', 'rubble', 'melted', 'crawls']\n",
      "Cluster 8\n",
      "['calling', 'helping', 'teaches', 'insults', 'encourages', 'inviting', 'attracts', 'manipulating', 'interviewing', 'enables', 'prompts', 'informing']\n",
      "Cluster 9\n",
      "['architect', 'idealistic', 'heir', 'inheritance', 'aristocrat', 'researcher']\n"
     ]
    }
   ],
   "source": [
    "# For the first 10 clusters\n",
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))\n",
    "\n",
    "for cluster in range(0,10):\n",
    "#     #\n",
    "#     # Print the cluster number  \n",
    "    print(\"Cluster %d\" % cluster)\n",
    "#     #\n",
    "#     # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in range(0,len(word_centroid_map.values())):\n",
    "        if( list(word_centroid_map.values())[i] == cluster ):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_centroids(wordlist, word_centroid_map):\n",
    "    num_centroids = max(list(word_centroid_map.values())) + 1\n",
    "    bag_of_centroids = np.zeros(num_centroids, dtype='float32')\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cetroids = np.zeros((train[\"review\"].size, num_clusters), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_cetroids[counter] = create_bag_of_centroids(review, word_centroid_map)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cetroids = np.zeros((test[\"review\"].size, num_clusters), dtype=\"float32\")\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_cetroids[counter] = create_bag_of_centroids(review, word_centroid_map)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# Fit a random forest and extract predictions \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(train_cetroids,train[\"sentiment\"])\n",
    "result = forest.predict(test_cetroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv( \"result_03_2.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
