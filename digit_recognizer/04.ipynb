{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 782\n",
    "np.random.seed(seed)\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df= pd.read_csv(\"./datasets/train.csv\")\n",
    "train = train_df.values\n",
    "test = pd.read_csv(\"./datasets/test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:, 1:]\n",
    "y_train = train[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x, mu, sigma):\n",
    "    \n",
    "    x_norm = np.zeros_like(x)\n",
    "\n",
    "    for n in range(len(x)):\n",
    "        for j in range(len(x[n])):\n",
    "            if(sigma[j]!=0):\n",
    "                x_norm[n,j] = (x[n,j] - mu[j]) / sigma[j]\n",
    "            else:\n",
    "                x_norm[n,j] = 0\n",
    "                    \n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X_train, axis = 0)\n",
    "sigma = np.max(X_train, axis=0) - np.min(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = normalization(test, mu, sigma)\n",
    "normalizer = Normalizer(norm='max')\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "test = normalizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def Relu(x, derivative=False):\n",
    "    if derivative == False:\n",
    "        return x * (x > 0)\n",
    "    else:\n",
    "        return 1 * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax(x):\n",
    "    x -= np.max(x)\n",
    "    sm = (np.exp(x).T / np.sum(np.exp(x),axis=1)).T\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWeightAndbiases():\n",
    "    n_inputs = 28 * 28\n",
    "    hidden1 = 30\n",
    "    n_outputs = 10\n",
    "    \n",
    "    # layer1\n",
    "    w1 = np.random.normal(0, n_inputs ** -0.5, [n_inputs, hidden1])\n",
    "    b1 = np.random.normal(0, n_inputs ** -0.5, [1, hidden1])\n",
    "    \n",
    "    w2 = np.random.normal(0, hidden1 ** -0.5, [hidden1, n_outputs])\n",
    "    b2 = np.random.normal(0, hidden1 ** -0.5, [1, n_outputs])\n",
    "    \n",
    "    return [w1, w2, b1, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dorpout\n",
    "def Dropout(x, dropout_percent):\n",
    "    data = [np.ones_like(x)]\n",
    "    mask = np.random.binomial( data, (1 - dropout_percent) )[0] / (1 - dropout_percent)  \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "def predict(weights, X, dropout_percent=0):\n",
    "    w1, w2, b1, b2 = weights\n",
    "    \n",
    "    first = Relu(np.dot(x, w1) + b1)\n",
    "    \n",
    "    return [first, Softmax(np.dot(first, w2) + b2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 衡量精确度\n",
    "def accuracy(output, y):\n",
    "    hit = 0\n",
    "    output = np.argmax(output, axis = 1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    for x, y in zip(output, y):\n",
    "        if(x == y):\n",
    "            hit += 1\n",
    "    p = (hit * 100) / output.shape[0]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    if x != 0:\n",
    "        return np.log(x)\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "def log(y):\n",
    "    return [[log2(nx) for nx in x] for x in y]\n",
    "\n",
    "def cost(Y_predict, Y_right, weights, nabla):\n",
    "    w1, w2, b1, b2 = weights\n",
    "    weights_sum_square = np.mean(w1 ** 2) + np.mean(w2 ** 2)\n",
    "    Loss = -np.mean(Y_right * log(Y_predict) + (1 - Y_right) * log(1 - Y_predict) + nabla / 2 * weights_sum_square)\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
